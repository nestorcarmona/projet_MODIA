{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet IA Frameworks 2023 - Partie 3\n",
    "@nestorhabibi @julien-blanchon @XuanMinhVuongNGUYEN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 0 : Librairies, Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# random\n",
    "import random\n",
    "\n",
    "# os\n",
    "import os\n",
    "\n",
    "# typing\n",
    "from typing_extensions import override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value: int):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # Numpy\n",
    "    torch.manual_seed(seed_value) # PyTorch\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des données\n",
    "interactions_test = pd.read_csv('../data/interactions_test.csv')\n",
    "interactions_train = pd.read_csv('../data/interactions_train.csv')\n",
    "RAW_interactions = pd.read_csv('../data/RAW_interactions.csv')\n",
    "RAW_recipes = pd.read_csv('../data/RAW_recipes.csv')\n",
    "test_script = pd.read_csv('../data/test_script.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user id and ratings\n",
    "df_interactions_train = interactions_train[['u', 'i', 'rating']].to_numpy(dtype=np.int64)\n",
    "\n",
    "# split train into train and validation\n",
    "# df_interactions_train, df_interactions_val = torch.utils.data.random_split(df_interactions_train, [0.80, 0.20])\n",
    "df_interactions_train, df_interactions_val = torch.utils.data.random_split(df_interactions_train, [0.99, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No overlap :(, the test set is broke\n",
    "# # Get the interactions_test with the u and i present in interactions_train\n",
    "# interactions_test_split = interactions_test[interactions_test[\"u\"].isin(interactions_train[\"u\"].values) & interactions_test[\"i\"].isin(interactions_train[\"i\"].values)]\n",
    "\n",
    "# df_interactions_test = interactions_test_split[['u', 'i', 'rating']].to_numpy(dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    df_interactions_train, \n",
    "    batch_size=512*4, \n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    df_interactions_val, \n",
    "    batch_size=512*4, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# testloader = torch.utils.data.DataLoader(\n",
    "#     df_interactions_test, \n",
    "#     batch_size=64*4, \n",
    "#     num_workers=2\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Import de la classe NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    \"\"\"Neural Collaborative Filtering (NCF)\n",
    "\n",
    "    Reference: \n",
    "    ----------\n",
    "    @article{he2017neural,\n",
    "        title     = {Neural Collaborative Filtering},\n",
    "        author    = {Xiangnan He and Lizi Liao and Hanwang Zhang and Liqiang Nie and Xia Hu and Tat-Seng Chua},\n",
    "        journal   = {The Web Conference},\n",
    "        year      = {2017},\n",
    "        doi       = {10.1145/3038912.3052569},\n",
    "        bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/ad42c33c299ef1c53dfd4697e3f7f98ed0ca31dd}\n",
    "    }\n",
    "    \"\"\"\n",
    "    def __init__(self, n_users: int, n_items: int, n_factors: int = 8, dropout: float = 0.20) -> None:\n",
    "        \"\"\"Neural Collaborative Filtering (NCF)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_users : int\n",
    "            Number of users for the embeddings layer.\n",
    "        n_items : int\n",
    "            Number of items for the embeddings layer.\n",
    "        n_factors : int, optional\n",
    "            Embeddings layer size, by default 8\n",
    "        dropout : float, optional\n",
    "            Dropout rate, by default 0.20\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Embedding layers\n",
    "        self.user_embeddings = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_embeddings = torch.nn.Embedding(n_items, n_factors)\n",
    "\n",
    "        # MLP layers\n",
    "        self.predictor = torch.nn.Sequential(\n",
    "            nn.Linear(in_features=n_factors*2 , out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    @override\n",
    "    def forward(self, user: torch.tensor, item: torch.tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : torch.tensor\n",
    "            User ids\n",
    "        item : torch.tensor\n",
    "            Item ids\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Predictions\n",
    "        \"\"\" \n",
    "        # Pass through embedding layers\n",
    "        user_emb = self.user_embeddings(user)\n",
    "        item_emb = self.item_embeddings(item)\n",
    "\n",
    "        # Concat the two embeddings\n",
    "        z = torch.cat([user_emb, item_emb], dim=-1)\n",
    "\n",
    "        # Pass through MLP\n",
    "        y = self.predictor(z)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Entraînement de NCF sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "if ((int(torch.__version__.split(\".\")[0]) >= 2) or (int(torch.__version__.split(\".\")[1]) >= 13)) and torch.has_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train(\n",
    "        model: NCF, \n",
    "        optimizer: torch.optim.Optimizer, \n",
    "        trainloader: torch.utils.data.DataLoader, \n",
    "        valloader: torch.utils.data.DataLoader,\n",
    "        epochs: int = 30\n",
    "    ) -> None:\n",
    "    \"\"\"Train the model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : NCF\n",
    "        The NCF model to train\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimizer to use\n",
    "    trainloader : torch.utils.data.DataLoader\n",
    "        The train dataloader\n",
    "    valloader : torch.utils.data.DataLoader\n",
    "        The validation dataloader\n",
    "    epochs : int, optional\n",
    "        Number of epochs to train, by default 30\n",
    "    \"\"\" \n",
    "    criterion_train = nn.MSELoss().to(device)\n",
    "    criterion_val = nn.L1Loss(reduction='mean').to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # initialize metrics\n",
    "        train_loss = []\n",
    "\n",
    "        for data in (pbar := tqdm(trainloader, unit=\" batch\", desc=f\"Train {epoch:03}\")):\n",
    "            data = data.to(device)\n",
    "            # get the data\n",
    "            users = data[:, 0]\n",
    "            items = data[:, 1]\n",
    "            ratings = data[:, 2]\n",
    "            # normalize the ratings\n",
    "            ratings = (ratings / 5)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass\n",
    "            y_hat = model(users, items)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion_train(y_hat.flatten(), ratings)\n",
    "\n",
    "            # backward pass + optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update metrics\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # update progress bar\n",
    "            pbar.set_postfix_str(f\"MSE train {5*loss.item():.3f}\")\n",
    "\n",
    "        # Evaluate the model on the val set\n",
    "        \n",
    "        model.eval() \n",
    "        valid_loss = []\n",
    "        for data in (pbar := tqdm(valloader, unit=\" batch\", desc=f\"Valid {epoch:03}\")):\n",
    "            # get the data\n",
    "            users = data[:, 0].to(torch.int).to(device)\n",
    "            items = data[:, 1].to(torch.int).to(device)\n",
    "            ratings = data[:, 2].to(torch.int).to(device)\n",
    "\n",
    "            # normalize the ratings\n",
    "            ratings = (ratings / 5)\n",
    "            with torch.no_grad():\n",
    "                y_hat = model(users, items)\n",
    "                # compute loss\n",
    "                loss = criterion_val(y_hat.flatten(), ratings)\n",
    "                valid_loss.append(loss.item())\n",
    "            \n",
    "            # update pbar\n",
    "            pbar.set_postfix_str(f\"MAE valid {5*loss.item():.3f}\")\n",
    "            \n",
    "    print(\"Final validation MAE:\", np.mean(valid_loss)*5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of unique user ids and ratings\n",
    "n_user = interactions_train['u'].max()+2\n",
    "n_items = interactions_train['i'].max()+2\n",
    "\n",
    "# define model\n",
    "model = NCF(n_user, n_items, n_factors=16).to(device)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 000: 100%|██████████| 338/338 [00:01<00:00, 170.19 batch/s, MSE train 0.167]\n",
      "Valid 000: 100%|██████████| 4/4 [00:00<00:00, 21.80 batch/s, MAE valid 0.553]\n",
      "Train 001: 100%|██████████| 338/338 [00:01<00:00, 246.93 batch/s, MSE train 0.183]\n",
      "Valid 001: 100%|██████████| 4/4 [00:00<00:00, 20.62 batch/s, MAE valid 0.554]\n",
      "Train 002: 100%|██████████| 338/338 [00:01<00:00, 241.03 batch/s, MSE train 0.176]\n",
      "Valid 002: 100%|██████████| 4/4 [00:00<00:00, 21.06 batch/s, MAE valid 0.553]\n",
      "Train 003: 100%|██████████| 338/338 [00:01<00:00, 252.44 batch/s, MSE train 0.171]\n",
      "Valid 003: 100%|██████████| 4/4 [00:00<00:00, 20.49 batch/s, MAE valid 0.545]\n",
      "Train 004: 100%|██████████| 338/338 [00:01<00:00, 246.21 batch/s, MSE train 0.160]\n",
      "Valid 004: 100%|██████████| 4/4 [00:00<00:00, 21.01 batch/s, MAE valid 0.534]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation MAE: 0.5583174712955952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train(\n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    trainloader=trainloader, \n",
    "    valloader=valloader,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(\n",
    "#         model: NCF, \n",
    "#         testloader: DataLoader\n",
    "#     ):\n",
    "#     model.eval()\n",
    "#     running_mae = 0\n",
    "#     with torch.no_grad():\n",
    "#         corrects = 0\n",
    "#         total = 0\n",
    "#         for data in (pbar := tqdm(testloader, total=len(testloader), unit=\" batch\", desc=f\"Test\")):\n",
    "#             # get the data\n",
    "#             users = data[:, 0].to(torch.int).to(device)\n",
    "#             items = data[:, 1].to(torch.int).to(device)\n",
    "#             r = data[:, 2].to(torch.int).to(device)\n",
    "\n",
    "#             r = (r / 5)\n",
    "#             y_hat = model(users, items).flatten()\n",
    "#             error = torch.abs(y_hat - r).sum().data\n",
    "            \n",
    "#             running_mae += error\n",
    "#             total += r.size(0)\n",
    "    \n",
    "#     mae = running_mae/total\n",
    "#     return (mae * 5).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights of the model\n",
    "torch.save(model.state_dict(), './weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = NCF(n_users=25077, n_items=178264, n_factors=16).to(device)\n",
    "model.load_state_dict(torch.load('./weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u = torch.from_numpy(interactions_train['u'].to_numpy()).to(device)\n",
    "X_i = torch.from_numpy(interactions_train['i'].to_numpy()).to(device)\n",
    "y = torch.from_numpy(interactions_train['rating'].to_numpy()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model(X_u, X_i)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6760, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the MAE between the predicted ratings and the true ratings on the 15k first samples\n",
    "mae = torch.abs(y_predict[:15000] - y[:15000]).mean()\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
