{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet IA Frameworks 2023 - Partie 3\n",
    "@nestorhabibi @julien-blanchon @XuanMinhVuongNGUYEN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 0 : Librairies, Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# random\n",
    "import random\n",
    "\n",
    "# os\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seeded.\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_RANDOM_SEED = 2021\n",
    "\n",
    "def seedBasic(seed=DEFAULT_RANDOM_SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# torch random seed\n",
    "import torch\n",
    "def seedTorch(seed=DEFAULT_RANDOM_SEED):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "      \n",
    "# basic + tensorflow + torch \n",
    "def seedEverything(seed=DEFAULT_RANDOM_SEED):\n",
    "    seedBasic(seed)\n",
    "    seedTorch(seed)\n",
    "    print('Everything seeded.')\n",
    "\n",
    "seedEverything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des données\n",
    "interactions_test = pd.read_csv('data/interactions_test.csv')\n",
    "interactions_train = pd.read_csv('data/interactions_train.csv')\n",
    "RAW_interactions = pd.read_csv('data/RAW_interactions.csv')\n",
    "RAW_recipes = pd.read_csv('data/RAW_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user id and ratings\n",
    "df_interactions_train = interactions_train[['user_id', 'recipe_id', 'rating']].to_numpy()\n",
    "df_interactions_test = interactions_test[['user_id', 'recipe_id', 'rating']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train into train and validation\n",
    "df_interactions_train, df_interactions_val = torch.utils.data.random_split(df_interactions_train, [0.80, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    df_interactions_train, \n",
    "    batch_size=512, \n",
    "    shuffle=True, \n",
    "    num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    df_interactions_val, \n",
    "    batch_size=512, \n",
    "    num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    df_interactions_test, \n",
    "    batch_size=64, \n",
    "    num_workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Import de la classe NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users: torch.tensor, n_items: torch.tensor, n_factors: int=8) -> None:\n",
    "        super().__init__()\n",
    "        # Embedding layers\n",
    "        self.user_embeddings = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_embeddings = torch.nn.Embedding(n_items, n_factors)\n",
    "\n",
    "        # MLP layers\n",
    "        self.predictor = torch.nn.Sequential(\n",
    "            nn.Linear(in_features=n_factors*2 , out_features=64),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, user: torch.tensor, item: torch.tensor) -> torch.Tensor:\n",
    "        # Pass through embedding layers\n",
    "        user_emb = self.user_embeddings(user)\n",
    "        item_emb = self.item_embeddings(item)\n",
    "\n",
    "        # Concat the two embeddings\n",
    "        z = torch.cat([user_emb, item_emb], dim=-1)\n",
    "\n",
    "        # Pass through MLP\n",
    "        y = self.predictor(z)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Entraînement de NCF sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "if ((int(torch.__version__.split(\".\")[0]) >= 2) or (int(torch.__version__.split(\".\")[1]) >= 13)) and torch.has_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from statistics import mean\n",
    "\n",
    "def train(\n",
    "        model: NCF, \n",
    "        optimizer: torch.optim.Optimizer, \n",
    "        trainloader: torch.utils.data.DataLoader, \n",
    "        valloader: torch.utils.data.DataLoader,\n",
    "        epochs: int = 30) -> None:\n",
    "    criterion_train = nn.MSELoss().to(device)\n",
    "    criterion_val = nn.L1Loss(reduction='sum').to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # initialize progress bar\n",
    "        pbar = tqdm(trainloader, total=len(trainloader), unit=\"batch\", desc=f\"Epoch {epoch: >5}\")\n",
    "        \n",
    "        # initialize metrics\n",
    "        train_loss = []\n",
    "\n",
    "        for i, data in enumerate(pbar):\n",
    "            # get the data\n",
    "            users = data[:, 0].to(torch.int).to(device)\n",
    "            items = data[:, 1].to(torch.int).to(device)\n",
    "            r = data[:, 2].to(torch.int).to(device)\n",
    "\n",
    "            # normalize the ratings\n",
    "            r = (r / 5)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass\n",
    "            y_hat = model(users, items)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion_train(y_hat.flatten(), r)\n",
    "\n",
    "            # backward pass + optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update metrics\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # update progress bar\n",
    "            pbar.set_postfix({\n",
    "                \"MSE train\": loss.item(),\n",
    "            })\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "        # Evaluate the model on the val set\n",
    "        model.eval() \n",
    "\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(valloader, total=len(valloader), unit=\"batch\", desc=f\"Val\")\n",
    "            for i, data in enumerate(pbar):\n",
    "                # get the data\n",
    "                users = data[:, 0].to(torch.int).to(device)\n",
    "                items = data[:, 1].to(torch.int).to(device)\n",
    "                r = data[:, 2].to(torch.int).to(device)\n",
    "\n",
    "                # normalize the ratings\n",
    "                r = (r / 5)\n",
    "\n",
    "                y_hat = model(users, items)\n",
    "\n",
    "                # compute loss\n",
    "                loss_val = criterion_val(y_hat.flatten(), r)\n",
    "            \n",
    "                # update pbar\n",
    "                pbar.set_postfix({\n",
    "                    \"MAE val\": loss_val.item(),\n",
    "                })\n",
    "\n",
    "        pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of unique user ids and ratings\n",
    "n_user = interactions_train['user_id'].nunique()\n",
    "n_items = interactions_train['recipe_id'].nunique()\n",
    "\n",
    "# to torch\n",
    "n_user = torch.tensor(n_user).to(device)\n",
    "n_items = torch.tensor(n_items).to(device)\n",
    "\n",
    "# define model\n",
    "model = NCF(n_user, n_items).to(device)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53181be83f0744c7ae2a6bc764f9c3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     0:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555bb14e5c2744b898e385be362550ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c104c73183744c448f8ec1639ef0fabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     1:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaefd85fa1f4c14bad9a1cf7229e70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7572837304425cb3d7ae8b94086010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     2:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0004be88159a47b08a5acfab31ae6b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d4a22c10ca4474a90bf9d1190c07a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     3:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984d6689708442b6849160cf5acd6445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a6bd9adb1640a599b94ed29e98094b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     4:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e4f95c2c41471da908c538827be64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0e8ed7f32240e081f78414e4df41a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     5:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4b6f120bac49dca088f9ee785069eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40624d8aa1e4441d847c03e933d938d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     6:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d360f07e7d4f7d932f6ee4363166bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48160ddcb531428cb8241955dec78797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     7:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4492e57658dc4db3b098e26d35ad621f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf4e0e5688c46e98502c5b2a79d4794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     8:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1140ebf2b0854d128fa7e63e98e4e6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ad13d854fe4170bae3ccfc02edcfe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch     9:   0%|          | 0/1093 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c839cb69f3f94952bdd5dd62c7993ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/274 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model\n",
    "train(\n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    trainloader=trainloader, \n",
    "    valloader=valloader,\n",
    "    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def test(model, testloader):\n",
    "    model.eval()\n",
    "    running_mae = 0\n",
    "    with torch.no_grad():\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "        pbar = tqdm(testloader, total=len(testloader), unit=\"batch\", desc=f\"Test\")\n",
    "        for i, data in enumerate(pbar):\n",
    "            # get the data\n",
    "            users = data[:, 0].to(torch.int).to(device)\n",
    "            items = data[:, 1].to(torch.int).to(device)\n",
    "            r = data[:, 2].to(torch.int).to(device)\n",
    "\n",
    "            r = (r / 5)\n",
    "            y_hat = model(users, items).flatten()\n",
    "            error = torch.abs(y_hat - r).sum().data\n",
    "            \n",
    "            running_mae += error\n",
    "            total += r.size(0)\n",
    "    \n",
    "    mae = running_mae/total\n",
    "    return (mae * 5).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8c79595d394e468362d2f98bca0639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/195 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.874189019203186"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights of the model\n",
    "torch.save(model.state_dict(), 'weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
