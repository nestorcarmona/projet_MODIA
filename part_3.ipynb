{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet IA Frameworks 2023 - Partie 3\n",
    "@nestorhabibi @julien-blanchon @XuanMinhVuongNGUYEN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 0 : Librairies, Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# random\n",
    "import random\n",
    "\n",
    "# os\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seeded.\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_RANDOM_SEED = 2021\n",
    "\n",
    "def seedBasic(seed=DEFAULT_RANDOM_SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# torch random seed\n",
    "import torch\n",
    "def seedTorch(seed=DEFAULT_RANDOM_SEED):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "      \n",
    "# basic + tensorflow + torch \n",
    "def seedEverything(seed=DEFAULT_RANDOM_SEED):\n",
    "    seedBasic(seed)\n",
    "    seedTorch(seed)\n",
    "    print('Everything seeded.')\n",
    "\n",
    "seedEverything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des données\n",
    "interactions_test = pd.read_csv('data/interactions_test.csv')\n",
    "interactions_train = pd.read_csv('data/interactions_train.csv')\n",
    "RAW_interactions = pd.read_csv('data/RAW_interactions.csv')\n",
    "RAW_recipes = pd.read_csv('data/RAW_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160901"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_train[\"recipe_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178262"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_train[\"i\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user id and ratings\n",
    "df_interactions_train = interactions_train[['u', 'i', 'rating']].to_numpy(dtype=np.int64)\n",
    "df_interactions_test = interactions_test[['u', 'i', 'rating']].to_numpy(dtype=np.int64)\n",
    "\n",
    "# split train into train and validation\n",
    "df_interactions_train, df_interactions_val = torch.utils.data.random_split(df_interactions_train, [0.80, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    df_interactions_train, \n",
    "    batch_size=512*4, \n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    df_interactions_val, \n",
    "    batch_size=512*4, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    df_interactions_test, \n",
    "    batch_size=64*4, \n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Import de la classe NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, n_users: int, n_items: int, n_factors: int = 8, dropout: float = 0.20) -> None:\n",
    "        super().__init__()\n",
    "        # Embedding layers\n",
    "        self.user_embeddings = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_embeddings = torch.nn.Embedding(n_items, n_factors)\n",
    "\n",
    "        # MLP layers\n",
    "        self.predictor = torch.nn.Sequential(\n",
    "            nn.Linear(in_features=n_factors*2 , out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, user: torch.tensor, item: torch.tensor) -> torch.Tensor:\n",
    "        # Pass through embedding layers\n",
    "        user_emb = self.user_embeddings(user)\n",
    "        item_emb = self.item_embeddings(item)\n",
    "\n",
    "        # Concat the two embeddings\n",
    "        z = torch.cat([user_emb, item_emb], dim=-1)\n",
    "\n",
    "        # Pass through MLP\n",
    "        y = self.predictor(z)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Entraînement de NCF sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "if ((int(torch.__version__.split(\".\")[0]) >= 2) or (int(torch.__version__.split(\".\")[1]) >= 13)) and torch.has_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train(\n",
    "        model: NCF, \n",
    "        optimizer: torch.optim.Optimizer, \n",
    "        trainloader: torch.utils.data.DataLoader, \n",
    "        valloader: torch.utils.data.DataLoader,\n",
    "        epochs: int = 30\n",
    "    ) -> None:\n",
    "    criterion_train = nn.MSELoss().to(device)\n",
    "    criterion_val = nn.L1Loss(reduction='mean').to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # initialize metrics\n",
    "        train_loss = []\n",
    "\n",
    "        for data in (pbar := tqdm(trainloader, unit=\" batch\", desc=f\"Train {epoch:03}\")):\n",
    "            data = data.to(device)\n",
    "            # get the data\n",
    "            users = data[:, 0]\n",
    "            items = data[:, 1]\n",
    "            ratings = data[:, 2]\n",
    "            # normalize the ratings\n",
    "            ratings = (ratings / 5)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass\n",
    "            y_hat = model(users, items)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion_train(y_hat.flatten(), ratings)\n",
    "\n",
    "            # backward pass + optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update metrics\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # update progress bar\n",
    "            pbar.set_postfix_str(f\"MSE train {5*loss.item():.3f}\")\n",
    "\n",
    "        # Evaluate the model on the val set\n",
    "        \n",
    "        model.eval() \n",
    "        valid_loss = []\n",
    "        for data in (pbar := tqdm(valloader, unit=\" batch\", desc=f\"Valid {epoch:03}\")):\n",
    "            # get the data\n",
    "            users = data[:, 0].to(torch.int).to(device)\n",
    "            items = data[:, 1].to(torch.int).to(device)\n",
    "            ratings = data[:, 2].to(torch.int).to(device)\n",
    "\n",
    "            # normalize the ratings\n",
    "            ratings = (ratings / 5)\n",
    "            with torch.no_grad():\n",
    "                y_hat = model(users, items)\n",
    "                # compute loss\n",
    "                loss = criterion_val(y_hat.flatten(), ratings)\n",
    "                valid_loss.append(loss.item())\n",
    "            \n",
    "            # update pbar\n",
    "            pbar.set_postfix_str(f\"MAE valid {5*loss.item():.3f}\")\n",
    "            \n",
    "    print(\"Final validation MAE:\", np.mean(valid_loss)*5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of unique user ids and ratings\n",
    "n_user = interactions_train['u'].max()+2\n",
    "n_items = interactions_train['i'].max()+2\n",
    "\n",
    "# define model\n",
    "model = NCF(n_user, n_items, n_factors=16).to(device)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 000: 100%|██████████| 274/274 [00:01<00:00, 233.54 batch/s, MSE train 0.072]\n",
      "Valid 000: 100%|██████████| 69/69 [00:00<00:00, 180.75 batch/s, MAE valid 0.576]\n",
      "Train 001: 100%|██████████| 274/274 [00:01<00:00, 216.07 batch/s, MSE train 0.495]\n",
      "Valid 001: 100%|██████████| 69/69 [00:00<00:00, 184.08 batch/s, MAE valid 0.581]\n",
      "Train 002: 100%|██████████| 274/274 [00:01<00:00, 219.70 batch/s, MSE train 0.338]\n",
      "Valid 002: 100%|██████████| 69/69 [00:00<00:00, 183.11 batch/s, MAE valid 0.576]\n",
      "Train 003: 100%|██████████| 274/274 [00:01<00:00, 202.22 batch/s, MSE train 0.077]\n",
      "Valid 003: 100%|██████████| 69/69 [00:00<00:00, 185.37 batch/s, MAE valid 0.572]\n",
      "Train 004: 100%|██████████| 274/274 [00:01<00:00, 208.66 batch/s, MSE train 0.242]\n",
      "Valid 004: 100%|██████████| 69/69 [00:00<00:00, 190.28 batch/s, MAE valid 0.563]\n",
      "Train 005: 100%|██████████| 274/274 [00:01<00:00, 203.42 batch/s, MSE train 0.026]\n",
      "Valid 005: 100%|██████████| 69/69 [00:00<00:00, 173.49 batch/s, MAE valid 0.556]\n",
      "Train 006: 100%|██████████| 274/274 [00:01<00:00, 202.44 batch/s, MSE train 0.076]\n",
      "Valid 006: 100%|██████████| 69/69 [00:00<00:00, 181.30 batch/s, MAE valid 0.542]\n",
      "Train 007: 100%|██████████| 274/274 [00:01<00:00, 219.94 batch/s, MSE train 0.276]\n",
      "Valid 007: 100%|██████████| 69/69 [00:00<00:00, 181.86 batch/s, MAE valid 0.548]\n",
      "Train 008: 100%|██████████| 274/274 [00:01<00:00, 233.68 batch/s, MSE train 0.291]\n",
      "Valid 008: 100%|██████████| 69/69 [00:00<00:00, 181.72 batch/s, MAE valid 0.540]\n",
      "Train 009: 100%|██████████| 274/274 [00:01<00:00, 241.77 batch/s, MSE train 0.188]\n",
      "Valid 009: 100%|██████████| 69/69 [00:00<00:00, 187.06 batch/s, MAE valid 0.534]\n",
      "Train 010: 100%|██████████| 274/274 [00:01<00:00, 235.11 batch/s, MSE train 0.123]\n",
      "Valid 010: 100%|██████████| 69/69 [00:00<00:00, 179.93 batch/s, MAE valid 0.529]\n",
      "Train 011: 100%|██████████| 274/274 [00:01<00:00, 239.42 batch/s, MSE train 0.039]\n",
      "Valid 011: 100%|██████████| 69/69 [00:00<00:00, 187.56 batch/s, MAE valid 0.526]\n",
      "Train 012: 100%|██████████| 274/274 [00:01<00:00, 235.42 batch/s, MSE train 0.150]\n",
      "Valid 012: 100%|██████████| 69/69 [00:00<00:00, 179.21 batch/s, MAE valid 0.527]\n",
      "Train 013: 100%|██████████| 274/274 [00:01<00:00, 238.82 batch/s, MSE train 0.211]\n",
      "Valid 013: 100%|██████████| 69/69 [00:00<00:00, 184.47 batch/s, MAE valid 0.525]\n",
      "Train 014: 100%|██████████| 274/274 [00:01<00:00, 199.50 batch/s, MSE train 0.196]\n",
      "Valid 014: 100%|██████████| 69/69 [00:00<00:00, 180.75 batch/s, MAE valid 0.525]\n",
      "Train 015: 100%|██████████| 274/274 [00:01<00:00, 210.46 batch/s, MSE train 0.045]\n",
      "Valid 015: 100%|██████████| 69/69 [00:00<00:00, 188.57 batch/s, MAE valid 0.531]\n",
      "Train 016: 100%|██████████| 274/274 [00:01<00:00, 189.69 batch/s, MSE train 0.048]\n",
      "Valid 016: 100%|██████████| 69/69 [00:00<00:00, 176.76 batch/s, MAE valid 0.532]\n",
      "Train 017: 100%|██████████| 274/274 [00:01<00:00, 207.31 batch/s, MSE train 0.082]\n",
      "Valid 017: 100%|██████████| 69/69 [00:00<00:00, 186.84 batch/s, MAE valid 0.536]\n",
      "Train 018: 100%|██████████| 274/274 [00:01<00:00, 245.86 batch/s, MSE train 0.088]\n",
      "Valid 018: 100%|██████████| 69/69 [00:00<00:00, 176.69 batch/s, MAE valid 0.539]\n",
      "Train 019: 100%|██████████| 274/274 [00:01<00:00, 246.33 batch/s, MSE train 0.032]\n",
      "Valid 019: 100%|██████████| 69/69 [00:00<00:00, 173.53 batch/s, MAE valid 0.542]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation MAE: 0.5299820022090622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train(\n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    trainloader=trainloader, \n",
    "    valloader=valloader,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "        model: NCF, \n",
    "        testloader: DataLoader\n",
    "    ):\n",
    "    model.eval()\n",
    "    running_mae = 0\n",
    "    with torch.no_grad():\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "        for data in (pbar := tqdm(testloader, total=len(testloader), unit=\" batch\", desc=f\"Test\")):\n",
    "            # get the data\n",
    "            users = data[:, 0].to(torch.int).to(device)\n",
    "            items = data[:, 1].to(torch.int).to(device)\n",
    "            r = data[:, 2].to(torch.int).to(device)\n",
    "\n",
    "            r = (r / 5)\n",
    "            y_hat = model(users, items).flatten()\n",
    "            error = torch.abs(y_hat - r).sum().data\n",
    "            \n",
    "            running_mae += error\n",
    "            total += r.size(0)\n",
    "    \n",
    "    mae = running_mae/total\n",
    "    return (mae * 5).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights of the model\n",
    "torch.save(model.state_dict(), 'weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
